{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deep Learning Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[-0.99768,-0.69574,-0.40373,-0.10236,0.22024,0.47742,0.82229]\n",
    "y=[2.0885,1.1646,0.3287,0.46013,0.44808,0.10013,-0.32952]\n",
    "\n",
    "input_data = pd.DataFrame(list(zip(x, y)), columns =['x', 'y']) \n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(input_data.x)\n",
    "y = input_data.y\n",
    "#scatter plot x and y\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.title(\"Input data\", fontsize=20)\n",
    "plt.scatter(x,y,s=50,c=\"g\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usual Regression Model building - Without Regualrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "x1 = sm.add_constant(x)\n",
    "m1 = sm.OLS(y,x1).fit()\n",
    "#SSE\n",
    "print(\"m1 SSE\", m1.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Order polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = sm.add_constant(np.column_stack([x,np.square(x)]))\n",
    "m2 = sm.OLS(y,x2).fit()\n",
    "print(\"m2 SSE\", m2.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fifth order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = sm.add_constant(np.column_stack([x, np.power(x,2),np.power(x,3),np.power(x,4),np.power(x,5)]))\n",
    "m3 = sm.OLS(y,x3).fit()\n",
    "print(\"m3 SSE\", m3.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model building - With Regualrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x3\n",
    "y = np.array(y)\n",
    "n_col = X.shape[1]\n",
    "d = np.identity(n_col)\n",
    "d[0,0] = 0\n",
    "w = []\n",
    "\n",
    "reg =0 \n",
    "w.append(np.linalg.lstsq(X.T.dot(X) + reg * d, X.T.dot(y))[0])\n",
    "\n",
    "reg =1 \n",
    "w.append(np.linalg.lstsq(X.T.dot(X) + reg * d, X.T.dot(y))[0])\n",
    "\n",
    "\n",
    "reg =10 \n",
    "w.append(np.linalg.lstsq(X.T.dot(X) + reg * d, X.T.dot(y))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regularized weights  lambda=0 \\n\", w[0])\n",
    "print(\"Regularized weights  lambda=1 \\n\", w[1])\n",
    "print(\"Regularized weights  lambda=10 \\n\", w[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new weights and older weights\n",
    "print(\"Regularized Weights With lambda = 0 \\n\", list(w[0]))\n",
    "print(\"Standard Weights With inbuilt package \\n\",list(m3.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploat all these three models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.title('Model results for different lambda values', fontsize=20)\n",
    "plt.scatter(x,y, s = 50, c = \"g\")\n",
    "x_new = np.linspace(x.min(), x.max(), 200)\n",
    "plt.plot(x_new, np.poly1d(np.polyfit(x, X.dot(w[0]), 5))(x_new),label='$\\lambda$ = 0', c = \"b\")\n",
    "plt.plot(x_new, np.poly1d(np.polyfit(x, X.dot(w[1]), 5))(x_new),label='$\\lambda$ = 1', c = \"r\")\n",
    "plt.plot(x_new, np.poly1d(np.polyfit(x, X.dot(w[2]), 5))(x_new),label='$\\lambda$ = 10', c = \"g\")\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the regularization Î»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights\n",
    "print(\"Final Weights \\n\", w[1])\n",
    "#perdiction\n",
    "pred = X.dot(w[1])\n",
    "##SSE\n",
    "SSE_Final = sum(np.square(y-pred))\n",
    "print(\"Final SSE \", SSE_Final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST data The data, shuffled and split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "num_classes=10\n",
    "x_train = X_train.reshape(60000, 784)\n",
    "x_test = X_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "## Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print(x_train.shape, 'train input samples')\n",
    "print(x_test.shape, 'test input samples')\n",
    "\n",
    "print(y_train.shape, 'train output samples')\n",
    "print(y_test.shape, 'test output samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(layers.Dense(128, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Results\n",
    "loss, acc = model.evaluate(x_train,  y_train, verbose=2)\n",
    "print(\"Train Accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"Test Accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model_r = keras.Sequential()\n",
    "model_r.add(layers.Dense(256, activation='sigmoid', input_shape=(784,), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_r.add(layers.Dense(128, activation='sigmoid',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_r.add(layers.Dense(10, activation='softmax'))\n",
    "model_r.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_r.fit(x_train, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Results\n",
    "loss, acc = model_r.evaluate(x_train,  y_train, verbose=2)\n",
    "print(\"Train Accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "loss, acc = model_r.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"Test Accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "model_rd = keras.Sequential()\n",
    "\n",
    "model_rd.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
    "model_rd.add(Dropout(0.7))\n",
    "\n",
    "model_rd.add(layers.Dense(128, activation='sigmoid'))\n",
    "model_rd.add(Dropout(0.6))\n",
    "\n",
    "model_rd.add(layers.Dense(10, activation='softmax'))\n",
    "model_rd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rd.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rd.fit(x_train, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Results\n",
    "loss, acc = model_rd.evaluate(x_train,  y_train, verbose=2)\n",
    "print(\"Train Accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "loss, acc = model_rd.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"Test Accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_re = keras.Sequential()\n",
    "model_re.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
    "model_re.add(layers.Dense(128, activation='sigmoid'))\n",
    "model_re.add(layers.Dense(10, activation='softmax'))\n",
    "model_re.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_re.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Enable saving checkpoints\n",
    "# Checkpoint the weights when validation accuracy improves\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "# checkpoint\n",
    "#dont forget to create a directory to store the checkpoints:\"early_stopping_checkpoints\"\n",
    "checkpoint = ModelCheckpoint(r\"D:\\Google Drive\\Training\\Book\\0.Chapters\\Chapter10 Deep Learning Hyperparameters\\4.Code\\epoch-{epoch:02d}.hdf5\")\n",
    "model_re.fit(x_train, y_train,epochs=10,validation_data=(x_test, y_test),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_re.load_weights(r\"D:\\Google Drive\\Training\\Book\\0.Chapters\\Chapter10 Deep Learning Hyperparameters\\4.Code\\\\epoch-07.hdf5\")# change the file name to the epoch you want to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_re = keras.Sequential()\n",
    "model_re.add(layers.Dense(256, activation='sigmoid', input_shape=(784,)))\n",
    "model_re.add(layers.Dense(128, activation='sigmoid'))\n",
    "model_re.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model_re.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                              min_delta=0.01,\n",
    "                              patience=2)\n",
    "\n",
    "#train the model with call back method\n",
    "model_re.fit(x_train, y_train, epochs=30,validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Dense(15, activation='sigmoid', input_shape=(784,)))\n",
    "model2.add(layers.Dense(15, activation='relu'))\n",
    "model2.add(layers.Dense(15, activation='tanh'))\n",
    "model2.add(layers.Dense(15, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(x_train, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model3.add(layers.Dense(20, activation='sigmoid'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "#High Learning Rate\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=10)\n",
    "model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model3.add(layers.Dense(20, activation='sigmoid'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "#Low learning rate\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.00001)\n",
    "model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model3.add(layers.Dense(20, activation='sigmoid'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "#Optimal learning rate\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model3.add(layers.Dense(20, activation='sigmoid'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "#Optimal learning rate\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.5)\n",
    "model3.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model4.add(layers.Dense(20, activation='sigmoid'))\n",
    "model4.add(layers.Dense(10, activation='softmax'))\n",
    "model4.summary()\n",
    "\n",
    "\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.5)\n",
    "model4.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Batch size=fll data(GD)\n",
    "model4.fit(x_train, y_train,batch_size=x_train.shape[0], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model4.add(layers.Dense(20, activation='sigmoid'))\n",
    "model4.add(layers.Dense(10, activation='softmax'))\n",
    "model4.summary()\n",
    "\n",
    "\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.5)\n",
    "model4.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Batch size=1 (SGD)\n",
    "model4.fit(x_train, y_train,batch_size=1, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(layers.Dense(20, activation='sigmoid', input_shape=(784,)))\n",
    "model4.add(layers.Dense(20, activation='sigmoid'))\n",
    "model4.add(layers.Dense(10, activation='softmax'))\n",
    "model4.summary()\n",
    "\n",
    "\n",
    "opt_new = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.5)\n",
    "model4.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Batch size = 512\n",
    "model4.fit(x_train, y_train,batch_size=512, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
